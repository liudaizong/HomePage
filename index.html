
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<!-- saved from url=(0023)http://www.skicyyu.org/ -->
<html>
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /> 
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org" /> 
  <meta name="google-site-verification" content="rKzHf6mgdcowi803peZ4PJMm_MtYczkhh7YrVLgcZCg" />
  <meta name="baidu-site-verification" content="16kZP2qtoA" />
  <style type="text/css">
      a {
      color: #1772d1;
      text-decoration:none;
      }
      a:focus, a:hover {
      color: #f09227;
      text-decoration:none;
      }
      body,td,th {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
      }
      strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px
      }
      heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 15px;
      font-weight: 700
      }
  </style> 
  <title>Daizong Liu, HUST</title> 
 </head> 
 <body>
  <table width="850" border="0" align="center" cellpadding="20"> 
   <tbody>
    <tr> 
     <td> 
      <table width="100%" align="center" border="0" cellpadding="10"> 
       <tbody>
        <tr> 
         <td width="67%" valign="middle"> 
          <p align="center"><font size="6">Daizong Liu</font></p> 
          <p align="justify"> I am a Master student in Huazhong University of Science and Technology. My research interests focus on the computer vision and artificical intelligence, specifically on the topic of video object segmentation and temporal sentence grounding. <br /> <br><strong>Email:</strong> dzliu&#64hust.edu.cn; daizongliu1996&#64gmail.com </br> <br /> <br /> </p> 
          <p align="center"> <a target="_blank" href="https://scholar.google.com/citations?user=lUw7tVIAAAAJ&hl=en">Google Scholar</a> </p> 
        </td> 
         <td width="20%"> <br /> <br /> <img width="210" src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=lUw7tVIAAAAJ&citpid=4" alt="Daizong Liu" /> 
         </td> 
        </tr> 
       </tbody>
      </table> 
      
      <!-- News --> 
      <table width="100%" align="left" border="0" cellspacing="0" cellpadding="5"> 
       <tbody>
        <tr> 
         <td width="100%" align="left"> <font size="5">News</font> 
          <!-- <font size="3">(for full publications, please see google scholars)</font> --> 
          <p> [2021.04] invited as a reviewer for <strong>ACM Multimedia 2021</strong>. <p>
          <p> [2021.03] One paper <strong>"Context-aware Biaffine Localizing Network for Temporal Sentence Grounding"</strong> has been accepted by  <strong>CVPR 2021</strong>.</p>
          <p> [2021.01] invited as a reviewer for <strong>IEEE Transactions on Multimedia</strong>. <p>
          <p> [2020.12] One paper <strong>"F2Net: Learning to Focus on the Foreground for Unsupervised Video Object Segmentation"</strong> has been accepted by <strong>AAAI 2021</strong>.</p>
          <p> [2020.12] One paper <strong>"Spatiotemporal Graph Neural Network based Mask Reconstruction for Video Object Segmentation"</strong> has been accepted by <strong>AAAI 2021</strong>.</p>
          <p> [2020.09] One paper <strong>"Reasoning Step-by-Step: Temporal Sentence Localization in Videos via Deep Rectification-Modulation Network"</strong> has been accepted by <strong>COLING 2020</strong>.</p>
          <p> [2020.08] I finish my internship at ByteDance AI Lab (Beijing).
          <p> [2020.07] One paper <strong>"Jointly Cross-and Self-Modal Graph Attention Network for Query-Based Moment Localization"</strong> has been accepted by <strong>ACMMM 2020</strong>.</p>
          <p> [2020.06] One paper <strong>"Video-based Facial Expression Recognition using Graph Convolutional Networks"</strong> has been accepted by <strong>ICPR 2020</strong>.</p>
          <p> [2020.05] One paper <strong>"SAANet: Siamese Action-units Attention Network for Improving Dynamic Facial Expression Recognition"</strong> has been accepted by <strong>Neurocomputing</strong>.</p>
          <p> [2019.03] One paper <strong>"MHP-VOS: Multiple hypotheses propagation for video object segmentation"</strong> has been accepted by <strong>CVPR 2019</strong> (Oral).</p>
          
  
         </td> 
        </tr> 
       </tbody>
      </table> <br /><br /> 

      <!-- Conference -->
      <table width="100%" align="left" border="0" cellspacing="0" cellpadding="5"> 
       <tbody>
        <tr> 
         <td width="100%" align="left"> <font size="5">Conference</font> 
          <!-- <font size="3">(for full publications, please see google scholars)</font> --> </td> 
        </tr> 
        <tr> 
        <tr> 
         <td width="100%" align="left"> <p> <b><a target="_blank" href="https://arxiv.org/abs/2103.11555">Context-aware Biaffine Localizing Network for Temporal Sentence Grounding</a> [<a target="_blank" href="https://arxiv.org/pdf/2103.11555.pdf">PDF</a>] </b><br /> <strong>Daizong Liu</strong>, Xiaoye Qu, Jianfeng Dong, Pan Zhou, Yu Cheng, Wei Wei, Zichuan Xu, Yulai Xie. <br /> <i>CVPR</i>, 2021 <br /></p> </td>
        </tr>
        <tr> 
         <td width="100%" align="left"> <p> <b><a target="_blank" href="https://arxiv.org/abs/2012.02534">F2Net: Learning to Focus on the Foreground for Unsupervised Video Object Segmentation</a> [<a target="_blank" href="https://arxiv.org/pdf/2012.02534.pdf">PDF</a>] </b><br /> <strong>Daizong Liu</strong>, Dongdong Yu, Changhu Wang, Pan Zhou. <br /> <i>AAAI</i>, 2021 <br /></p> </td>
        </tr>
        <tr> 
         <td width="100%" align="left"> <p> <b><a target="_blank" href="https://arxiv.org/abs/2012.05499">Spatiotemporal Graph Neural Network based Mask Reconstruction for Video Object Segmentation</a> [<a target="_blank" href="https://arxiv.org/pdf/2012.05499.pdf">PDF</a>] </b><br /> <strong>Daizong Liu</strong>, Shuangjie Xu, Xiao-Yang Liu, Zichuan Xu, Wei Wei, Pan Zhou. <br /> <i>AAAI</i>, 2021 <br /></p> </td>
        </tr>
        <tr> 
         <td width="100%" align="left"> <p> <b><a target="_blank" href="https://www.aclweb.org/anthology/2020.coling-main.167/">Reasoning Step-by-Step: Temporal Sentence Localization in Videos via Deep Rectification-Modulation Network</a> [<a target="_blank" href="https://www.aclweb.org/anthology/2020.coling-main.167.pdf">PDF</a>] </b><br /> <strong>Daizong Liu</strong>, Xiaoye Qu, Jianfeng Dong, Pan Zhou <br /> <i>COLING</i>, 2020 <br /></p> </td>
        </tr>
        <tr> 
         <td width="100%" align="left"> <p> <b><a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3394171.3414026">Jointly Cross-and Self-Modal Graph Attention Network for Query-Based Moment Localization</a> [<a target="_blank" href="https://arxiv.org/pdf/2008.01403.pdf">PDF</a>] </b><br /> <strong>Daizong Liu</strong>, Xiaoye Qu, Xiao-Yang Liu, Jianfeng Dong, Pan Zhou, Zichuan Xu. <br /> <i>ACM MM</i>, 2020 <br /></p> </td>
        </tr>
        <tr> 
         <td width="100%" align="left"> <p> <b><a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9413094">Video-based Facial Expression Recognition using Graph Convolutional Networks</a> [<a target="_blank" href="https://arxiv.org/pdf/2010.13386.pdf">PDF</a>] </b><br /> <strong>Daizong Liu</strong>, Hongting Zhang, Pan Zhou. <br /> <i>ICPR</i>, 2020 <br /></p> </td>
        </tr>
        <tr> 
         <td width="100%" align="left"> <p> <b><a target="_blank" href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_MHP-VOS_Multiple_Hypotheses_Propagation_for_Video_Object_Segmentation_CVPR_2019_paper.html">MHP-VOS: Multiple hypotheses propagation for video object segmentation</a> [<a target="_blank" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Xu_MHP-VOS_Multiple_Hypotheses_Propagation_for_Video_Object_Segmentation_CVPR_2019_paper.pdf">PDF</a>] </b><br /> Shuangjie Xu<strong>&dagger;</strong>, <strong>Daizong Liu</strong><strong>&dagger;</strong>, Linchao Bao, Wei Liu, Pan Zhou. <br /> <i>CVPR</i>, 2019 <br /></p> </td>
        </tr>
        
       </tbody>
      </table> <br /><br /> 

      <!-- Journal -->
      <table width="100%" align="left" border="0" cellspacing="0" cellpadding="5"> 
       <tbody>
        <tr> 
         <td width="100%" align="left"> <font size="5">Journal</font> 
          <!-- <font size="3">(for full publications, please see google scholars)</font> --> </td> 
        </tr> 
        <tr> 
         <td width="100%" align="left"> <p> <b><a href="https://www.sciencedirect.com/science/article/abs/pii/S092523122031050X">SAANet: Siamese action-units attention network for improving dynamic facial expression recognition</a> [<a target="_blank" href="https://reader.elsevier.com/reader/sd/pii/S092523122031050X?token=0BE50224C902B3EB4704031FA33E3A5A8EFE0FE81D9A30302B249DA3E174236534AC82EF4281D764580E2D526CD0AD79&originRegion=us-east-1&originCreation=20210511025659">PDF</a>] </b><br /> <strong>Daizong Liu</strong>, Xi Ouyang, Shuangjie Xu, Pan Zhou, Kun He, Shiping Wen<br /> <i>Neurocomputing</i>, 2020 <br /> </p> </td> 
        </tr> 

       </tbody>
      </table> 
      
      <!-- Links -->
      <table width="100%" align="left" border="0" cellspacing="0" cellpadding="5"> 
       <tbody>
        <tr> 
         <td width="100%" align="left"> <font size="5">Links</font> 
          <!-- <font size="3">(for full publications, please see google scholars)</font> --> </td> 
        </tr> 
        <tr> 
         <td width="100%" align="left"> 
          <p> My Github: <a target="_blank" href="https://github.com/liudaizong">Daizong Liu (刘岱宗)</a> </p>
<!--           <p> 友情链接: <a target="_blank" href="https://7color94.github.io/">Kai Su (苏凯)</a>, <a target="_blank" href="http://chw.azurewebsites.net/">Changhu Wang (王长虎)</a> </p> -->
         </td> 
        </tr> 
       </tbody>
      </table>

      
    </tr>
   </tbody>
  </table>
 </body>
</html>
